{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "from mxnet import autograd\n",
    "\n",
    "class Residual(nn.Block):\n",
    "    def __init__(self, channels, same_shape=True, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.same_shape = same_shape\n",
    "        strides = 1 if same_shape else 2\n",
    "        self.conv1 = nn.Conv2D(channels, kernel_size=3, padding=1,\n",
    "                              strides=strides)\n",
    "        self.bn1 = nn.BatchNorm()\n",
    "        self.conv2 = nn.Conv2D(channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        if not same_shape:\n",
    "            self.conv3 = nn.Conv2D(channels, kernel_size=1,\n",
    "                                  strides=strides)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nd.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if not self.same_shape:\n",
    "            x = self.conv3(x)\n",
    "        return nd.relu(out + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 6, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3)\n",
    "blk.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(4, 3, 6, 6))\n",
    "blk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk2 = Residual(8, same_shape=False)\n",
    "blk2.initialize()\n",
    "blk2(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Block):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        # add name_scope on the outermost Sequential\n",
    "        with self.name_scope():\n",
    "            # block 1\n",
    "            b1 = nn.Conv2D(64, kernel_size=3, strides=1)\n",
    "            # block 2\n",
    "            b2 = nn.Sequential()\n",
    "            b2.add(\n",
    "                nn.MaxPool2D(pool_size=3, strides=1),\n",
    "                Residual(64),\n",
    "            )\n",
    "            \n",
    "            # block 6\n",
    "            b6 = nn.Sequential()\n",
    "            b6.add(\n",
    "                nn.AvgPool2D(pool_size=3),\n",
    "                nn.Dense(num_classes)\n",
    "            )\n",
    "            # chain all blocks together\n",
    "            self.net = nn.Sequential()\n",
    "            self.net.add(b1, b2, b6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i, b in enumerate(self.net):\n",
    "            out = b(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d output: %s'%(i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 output: (4, 64, 6, 6)\n",
      "Block 2 output: (4, 64, 4, 4)\n",
      "Block 3 output: (4, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet(17, verbose=True)\n",
    "net.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(4, 1, 8, 8))\n",
    "y = net(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('data.json', 'r').read()\n",
    "dataset = json.loads(dataset)\n",
    "dataset[0] = nd.array([np.array(l) for l in dataset[0]])\n",
    "dataset[1] = nd.array([np.array(l) for l in dataset[1]])\n",
    "X = dataset[0]\n",
    "y = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.   0.   0.  ...,  0.   0.  -1. ]\n",
       " [ 0.   0.   0.  ...,  0.   0.  -1. ]\n",
       " [ 0.   0.   0.  ...,  0.   0.  -1. ]\n",
       " ..., \n",
       " [ 0.   0.5  0.  ...,  0.   0.  -1. ]\n",
       " [ 0.   0.   0.  ...,  0.   0.  -1. ]\n",
       " [ 0.   1.   0.  ...,  0.   0.  -1. ]]\n",
       "<NDArray 60x65 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 8\n"
     ]
    }
   ],
   "source": [
    "m = int(X.shape[0])\n",
    "n = int(X.shape[1])\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_X = nd.reshape(X, (m,1,n,n))\n",
    "temp_y = nd.reshape(y, (m,n*n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"return data and label on ctx\"\"\"\n",
    "    if isinstance(batch, mx.io.DataBatch):\n",
    "        data = batch.data[0]\n",
    "        label = batch.label[0]\n",
    "    else:\n",
    "        data, label = batch\n",
    "    return (gluon.utils.split_and_load(data, ctx),\n",
    "            gluon.utils.split_and_load(label, ctx),\n",
    "            data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from time import time\n",
    "def train(train_data, test_data, net, loss, trainer, ctx, num_epochs, print_batches=None):\n",
    "    \"\"\"Train a network\"\"\"\n",
    "    print(\"Start training on \", ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc, n, m = 0.0, 0.0, 0.0, 0.0\n",
    "        if isinstance(train_data, mx.io.MXDataIter):\n",
    "            train_data.reset()\n",
    "        start = time()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data, label, batch_size = _get_batch(batch, ctx)\n",
    "            losses = []\n",
    "            with autograd.record():\n",
    "                outputs = [net(X) for X in data]\n",
    "                losses = [loss(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "            for l in losses:\n",
    "                l.backward()\n",
    "            train_loss += sum([l.sum().asscalar() for l in losses])\n",
    "            trainer.step(batch_size)\n",
    "            n += batch_size\n",
    "            m += sum([y.size for y in label])\n",
    "            if print_batches and (i+1) % print_batches == 0:\n",
    "                print(\"Batch %d. Loss: %f\" % (\n",
    "                    n, train_loss/n\n",
    "                ))\n",
    "\n",
    "        print(\"Epoch %d. Loss: %.3f, Time %.1f sec\" % (\n",
    "            epoch, train_loss/n, time() - start\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  cpu(0)\n",
      "Epoch 0. Loss: 0.036, Time 0.1 sec\n",
      "Epoch 1. Loss: 0.005, Time 0.1 sec\n",
      "Epoch 2. Loss: 0.003, Time 0.1 sec\n",
      "Epoch 3. Loss: 0.002, Time 0.1 sec\n",
      "Epoch 4. Loss: 0.002, Time 0.1 sec\n",
      "Epoch 5. Loss: 0.002, Time 0.1 sec\n",
      "Epoch 6. Loss: 0.002, Time 0.1 sec\n",
      "Epoch 7. Loss: 0.002, Time 0.2 sec\n",
      "Epoch 8. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 9. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 10. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 11. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 12. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 13. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 14. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 15. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 16. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 17. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 18. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 19. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 20. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 21. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 22. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 23. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 24. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 25. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 26. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 27. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 28. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 29. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 30. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 31. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 32. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 33. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 34. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 35. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 36. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 37. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 38. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 39. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 40. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 41. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 42. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 43. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 44. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 45. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 46. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 47. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 48. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 49. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 50. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 51. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 52. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 53. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 54. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 55. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 56. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 57. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 58. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 59. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 60. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 61. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 62. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 63. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 64. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 65. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 66. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 67. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 68. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 69. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 70. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 71. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 72. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 73. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 74. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 75. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 76. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 77. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 78. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 79. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 80. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 81. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 82. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 83. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 84. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 85. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 86. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 87. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 88. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 89. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 90. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 91. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 92. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 93. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 94. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 95. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 96. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 97. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 98. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 99. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 100. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 101. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 102. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 103. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 104. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 105. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 106. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 107. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 108. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 109. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 110. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 111. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 112. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 113. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 114. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 115. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 116. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 117. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 118. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 119. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 120. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 121. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 122. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 123. Loss: 0.001, Time 0.5 sec\n",
      "Epoch 124. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 125. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 126. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 127. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 128. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 129. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 130. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 131. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 132. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 133. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 134. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 135. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 136. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 137. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 138. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 139. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 140. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 141. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 142. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 143. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 144. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 145. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 146. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 147. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 148. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 149. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 150. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 151. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 152. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 153. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 154. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 155. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 156. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 157. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 158. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 159. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 160. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 161. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 162. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 163. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 164. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 165. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 166. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 167. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 168. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 169. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 170. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 171. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 172. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 173. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 174. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 175. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 176. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 177. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 178. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 179. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 180. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 181. Loss: 0.001, Time 0.4 sec\n",
      "Epoch 182. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 183. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 184. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 185. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 186. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 187. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 188. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 189. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 190. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 191. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 192. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 193. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 194. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 195. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 196. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 197. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 198. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 199. Loss: 0.001, Time 0.1 sec\n",
      "Epoch 200. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 201. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 202. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 203. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 204. Loss: 0.001, Time 0.7 sec\n",
      "Epoch 205. Loss: 0.000, Time 0.4 sec\n",
      "Epoch 206. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 207. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 208. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 209. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 210. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 211. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 212. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 213. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 214. Loss: 0.001, Time 0.2 sec\n",
      "Epoch 215. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 216. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 217. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 218. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 219. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 220. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 221. Loss: 0.000, Time 0.4 sec\n",
      "Epoch 222. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 223. Loss: 0.000, Time 0.1 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 225. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 226. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 227. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 228. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 229. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 230. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 231. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 232. Loss: 0.000, Time 0.4 sec\n",
      "Epoch 233. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 234. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 235. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 236. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 237. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 238. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 239. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 240. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 241. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 242. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 243. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 244. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 245. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 246. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 247. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 248. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 249. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 250. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 251. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 252. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 253. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 254. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 255. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 256. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 257. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 258. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 259. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 260. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 261. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 262. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 263. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 264. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 265. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 266. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 267. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 268. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 269. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 270. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 271. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 272. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 273. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 274. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 275. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 276. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 277. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 278. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 279. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 280. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 281. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 282. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 283. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 284. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 285. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 286. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 287. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 288. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 289. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 290. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 291. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 292. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 293. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 294. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 295. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 296. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 297. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 298. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 299. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 300. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 301. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 302. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 303. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 304. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 305. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 306. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 307. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 308. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 309. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 310. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 311. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 312. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 313. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 314. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 315. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 316. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 317. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 318. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 319. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 320. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 321. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 322. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 323. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 324. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 325. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 326. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 327. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 328. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 329. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 330. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 331. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 332. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 333. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 334. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 335. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 336. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 337. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 338. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 339. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 340. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 341. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 342. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 343. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 344. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 345. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 346. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 347. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 348. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 349. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 350. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 351. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 352. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 353. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 354. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 355. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 356. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 357. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 358. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 359. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 360. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 361. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 362. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 363. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 364. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 365. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 366. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 367. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 368. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 369. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 370. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 371. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 372. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 373. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 374. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 375. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 376. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 377. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 378. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 379. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 380. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 381. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 382. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 383. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 384. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 385. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 386. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 387. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 388. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 389. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 390. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 391. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 392. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 393. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 394. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 395. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 396. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 397. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 398. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 399. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 400. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 401. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 402. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 403. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 404. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 405. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 406. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 407. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 408. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 409. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 410. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 411. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 412. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 413. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 414. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 415. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 416. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 417. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 418. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 419. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 420. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 421. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 422. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 423. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 424. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 425. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 426. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 427. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 428. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 429. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 430. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 431. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 432. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 433. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 434. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 435. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 436. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 437. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 438. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 439. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 440. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 441. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 442. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 443. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 444. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 445. Loss: 0.000, Time 0.1 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 447. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 448. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 449. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 450. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 451. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 452. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 453. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 454. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 455. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 456. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 457. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 458. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 459. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 460. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 461. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 462. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 463. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 464. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 465. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 466. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 467. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 468. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 469. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 470. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 471. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 472. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 473. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 474. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 475. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 476. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 477. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 478. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 479. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 480. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 481. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 482. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 483. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 484. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 485. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 486. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 487. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 488. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 489. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 490. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 491. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 492. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 493. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 494. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 495. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 496. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 497. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 498. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 499. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 500. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 501. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 502. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 503. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 504. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 505. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 506. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 507. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 508. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 509. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 510. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 511. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 512. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 513. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 514. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 515. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 516. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 517. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 518. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 519. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 520. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 521. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 522. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 523. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 524. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 525. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 526. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 527. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 528. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 529. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 530. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 531. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 532. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 533. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 534. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 535. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 536. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 537. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 538. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 539. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 540. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 541. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 542. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 543. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 544. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 545. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 546. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 547. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 548. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 549. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 550. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 551. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 552. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 553. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 554. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 555. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 556. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 557. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 558. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 559. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 560. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 561. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 562. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 563. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 564. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 565. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 566. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 567. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 568. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 569. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 570. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 571. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 572. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 573. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 574. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 575. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 576. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 577. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 578. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 579. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 580. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 581. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 582. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 583. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 584. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 585. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 586. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 587. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 588. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 589. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 590. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 591. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 592. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 593. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 594. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 595. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 596. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 597. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 598. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 599. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 600. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 601. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 602. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 603. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 604. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 605. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 606. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 607. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 608. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 609. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 610. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 611. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 612. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 613. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 614. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 615. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 616. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 617. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 618. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 619. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 620. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 621. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 622. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 623. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 624. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 625. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 626. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 627. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 628. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 629. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 630. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 631. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 632. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 633. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 634. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 635. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 636. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 637. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 638. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 639. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 640. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 641. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 642. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 643. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 644. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 645. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 646. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 647. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 648. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 649. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 650. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 651. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 652. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 653. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 654. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 655. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 656. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 657. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 658. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 659. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 660. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 661. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 662. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 663. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 664. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 665. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 666. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 667. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 668. Loss: 0.000, Time 0.1 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 670. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 671. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 672. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 673. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 674. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 675. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 676. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 677. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 678. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 679. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 680. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 681. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 682. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 683. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 684. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 685. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 686. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 687. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 688. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 689. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 690. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 691. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 692. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 693. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 694. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 695. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 696. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 697. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 698. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 699. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 700. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 701. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 702. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 703. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 704. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 705. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 706. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 707. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 708. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 709. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 710. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 711. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 712. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 713. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 714. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 715. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 716. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 717. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 718. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 719. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 720. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 721. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 722. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 723. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 724. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 725. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 726. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 727. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 728. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 729. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 730. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 731. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 732. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 733. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 734. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 735. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 736. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 737. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 738. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 739. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 740. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 741. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 742. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 743. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 744. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 745. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 746. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 747. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 748. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 749. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 750. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 751. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 752. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 753. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 754. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 755. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 756. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 757. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 758. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 759. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 760. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 761. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 762. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 763. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 764. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 765. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 766. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 767. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 768. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 769. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 770. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 771. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 772. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 773. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 774. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 775. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 776. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 777. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 778. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 779. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 780. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 781. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 782. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 783. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 784. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 785. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 786. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 787. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 788. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 789. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 790. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 791. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 792. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 793. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 794. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 795. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 796. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 797. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 798. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 799. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 800. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 801. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 802. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 803. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 804. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 805. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 806. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 807. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 808. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 809. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 810. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 811. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 812. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 813. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 814. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 815. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 816. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 817. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 818. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 819. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 820. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 821. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 822. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 823. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 824. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 825. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 826. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 827. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 828. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 829. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 830. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 831. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 832. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 833. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 834. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 835. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 836. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 837. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 838. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 839. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 840. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 841. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 842. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 843. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 844. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 845. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 846. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 847. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 848. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 849. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 850. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 851. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 852. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 853. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 854. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 855. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 856. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 857. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 858. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 859. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 860. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 861. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 862. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 863. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 864. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 865. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 866. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 867. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 868. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 869. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 870. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 871. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 872. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 873. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 874. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 875. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 876. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 877. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 878. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 879. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 880. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 881. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 882. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 883. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 884. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 885. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 886. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 887. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 888. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 889. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 890. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 891. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 892. Loss: 0.000, Time 0.1 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 894. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 895. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 896. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 897. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 898. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 899. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 900. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 901. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 902. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 903. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 904. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 905. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 906. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 907. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 908. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 909. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 910. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 911. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 912. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 913. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 914. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 915. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 916. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 917. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 918. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 919. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 920. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 921. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 922. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 923. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 924. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 925. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 926. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 927. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 928. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 929. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 930. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 931. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 932. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 933. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 934. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 935. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 936. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 937. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 938. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 939. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 940. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 941. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 942. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 943. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 944. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 945. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 946. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 947. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 948. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 949. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 950. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 951. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 952. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 953. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 954. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 955. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 956. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 957. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 958. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 959. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 960. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 961. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 962. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 963. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 964. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 965. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 966. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 967. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 968. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 969. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 970. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 971. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 972. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 973. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 974. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 975. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 976. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 977. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 978. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 979. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 980. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 981. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 982. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 983. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 984. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 985. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 986. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 987. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 988. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 989. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 990. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 991. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 992. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 993. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 994. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 995. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 996. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 997. Loss: 0.000, Time 0.1 sec\n",
      "Epoch 998. Loss: 0.000, Time 0.2 sec\n",
      "Epoch 999. Loss: 0.000, Time 0.1 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "\n",
    "\n",
    "datasetTrain = gluon.data.ArrayDataset(temp_X[:int(m*0.8)], temp_y[:int(m*0.8)])\n",
    "datasetTest = gluon.data.ArrayDataset(temp_X[int(m*0.8):], temp_y[int(m*0.8):])\n",
    "\n",
    "train_data = utils.DataLoader(datasetTrain, batch_size = 4, shuffle = True)\n",
    "test_data = utils.DataLoader(datasetTest, batch_size = 4, shuffle = True)\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net = ResNet(n*n+1)\n",
    "net.initialize(ctx=ctx, init=init.Xavier())\n",
    "\n",
    "# \n",
    "loss = gluon.loss.L2Loss()\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'sgd', {'learning_rate': 0.5})\n",
    "train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=1000)\n",
    "# epochs = 5\n",
    "# batch_size = 10\n",
    "# for e in range(epochs):\n",
    "#     total_loss = 0\n",
    "#     for data, label in data_iter:\n",
    "#         with autograd.record():\n",
    "#             output = net(data)\n",
    "#             loss = square_loss(output, label)\n",
    "#         loss.backward()\n",
    "#         trainer.step(batch_size)\n",
    "#         total_loss += nd.sum(loss).asscalar()\n",
    "#     print(\"Epoch %d, average loss: %f\" % (e, total_loss/num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[  4.23843414e-03  -1.11521259e-02   1.31375883e-02   9.09030885e-02\n",
      "  -8.60948674e-03  -8.17036442e-03  -7.99241848e-03   1.11951800e-02\n",
      "  -2.86042634e-02   9.37412307e-02  -1.33569017e-02  -1.98139809e-04\n",
      "  -6.56664744e-03   2.11453866e-02   1.61224902e-02   5.44572901e-03\n",
      "  -9.84130893e-03   2.60841157e-02  -6.63036387e-03  -2.62511708e-03\n",
      "   8.81136954e-02  -1.19086877e-02   8.13862085e-02   2.90096924e-03\n",
      "   1.62075944e-02   2.29083560e-02   1.23490170e-02  -7.67406076e-03\n",
      "  -4.48686443e-03  -8.86567682e-03   1.03991807e-01   2.20773350e-02\n",
      "  -3.47914994e-02   3.45115550e-03   7.90653378e-02   4.17295285e-03\n",
      "  -7.12510757e-03   1.48338163e-02  -1.52116455e-03  -1.16411895e-02\n",
      "  -1.06487442e-02   8.00879672e-02   6.27601054e-03   7.39737554e-03\n",
      "   1.55500900e-02   7.41975382e-04   1.21987723e-02  -4.63728327e-03\n",
      "  -1.78602338e-02   3.73544507e-02   1.15138814e-01   9.90186855e-02\n",
      "   9.47135165e-02  -6.96273986e-03  -1.15268920e-02   1.58146881e-02\n",
      "  -1.78446155e-03   1.04648145e-02  -2.33185478e-03   1.68702584e-02\n",
      "   1.12116272e-02  -1.39074493e-02  -1.98040716e-03  -5.70598617e-03\n",
      "  -9.86694276e-01]\n",
      "<NDArray 65 @cpu(0)>\n",
      "\n",
      "[ 0.          0.          0.          0.09892899  0.          0.          0.\n",
      "  0.          0.          0.10570208  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.09586933  0.          0.09350219  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.11067268  0.          0.          0.\n",
      "  0.0877677   0.          0.          0.          0.          0.          0.\n",
      "  0.09692284  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.11196952  0.10071122  0.09795345  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.        ]\n",
      "<NDArray 65 @cpu(0)>\n",
      "\n",
      "[ 0.         -0.          0.          0.09090309 -0.         -0.         -0.\n",
      "  0.         -0.          0.09374123 -0.         -0.         -0.          0.\n",
      "  0.          0.         -0.          0.         -0.         -0.          0.0881137\n",
      " -0.          0.08138621  0.          0.          0.          0.         -0.\n",
      " -0.         -0.          0.10399181  0.         -0.          0.\n",
      "  0.07906534  0.         -0.          0.         -0.         -0.         -0.\n",
      "  0.08008797  0.          0.          0.          0.          0.         -0.\n",
      " -0.          0.          0.11513881  0.09901869  0.09471352 -0.         -0.\n",
      "  0.         -0.          0.         -0.          0.          0.         -0.\n",
      " -0.         -0.         -0.98669428]\n",
      "<NDArray 65 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_data:\n",
    "    pprint(net(i)[0])\n",
    "    pprint(j[0])\n",
    "    mask = j[0] != 0\n",
    "    print(nd.multiply(net(i)[0],mask))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
